# ðŸŽ“ Student Performance Prediction â€” End-to-End Machine Learning Pipeline

## Overview

This project implements a reproducible, end-to-end machine learning pipeline for predicting student academic performance using a multiclass classification approach. The system is designed with production-style engineering practices, focusing not only on prediction accuracy but also on clean architecture, reproducibility, and controlled experimentation.

Unlike notebook-based or one-off implementations, this project treats machine learning as a complete system, covering the full lifecycle from raw data ingestion to evaluation, reporting, logging, and automated testing.

---

## Key Objectives

- Predict student academic performance categories (LOW / MEDIUM / HIGH)
- Compare multiple machine learning algorithms under identical experimental conditions
- Ensure reproducibility through configuration-driven execution
- Demonstrate industry-aligned ML engineering practices suitable for a capstone project

---

## System Highlights

- End-to-end pipeline: ingestion â†’ validation â†’ feature engineering â†’ training â†’ evaluation â†’ reporting
- Fully config-driven using YAML files
- Reproducible experiments with deterministic outputs
- Clear separation of concerns across pipeline stages
- Automated metric generation and visualization
- Structured logging for traceability and debugging
- Automated tests for core pipeline contracts

---

## Algorithms Used

The following algorithms are trained and evaluated on the same dataset split and preprocessing pipeline:

1. Logistic Regression  
2. Decision Tree  
3. Random Forest  
4. Support Vector Machine (SVM)  
5. XGBoost  

Performance is compared using accuracy, confusion matrices, and macro-averaged metrics.

---

## Project Structure

student-performance-system/
â”‚
â”œâ”€â”€ main.py                     # CLI orchestrator
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/              # Data loading
â”‚   â”œâ”€â”€ labels/                 # Target label derivation
â”‚   â”œâ”€â”€ validation/             # Schema-based validation
â”‚   â”œâ”€â”€ features/               # Feature engineering
â”‚   â”œâ”€â”€ preprocessing/          # Scaling and cleaning
â”‚   â”œâ”€â”€ split/                  # Train-test split
â”‚   â”œâ”€â”€ models/                 # Model abstractions and trainers
â”‚   â”œâ”€â”€ evaluation/             # Metrics computation
â”‚   â”œâ”€â”€ reporting/              # CSV and plot generation
â”‚   â””â”€â”€ utils/                  # Logging utilities
â”‚
â”œâ”€â”€ configs/                    # YAML configuration files
â”‚   â”œâ”€â”€ experiment.yaml
â”‚   â”œâ”€â”€ schema.yaml
â”‚   â”œâ”€â”€ labels.yaml
â”‚   â”œâ”€â”€ features.yaml
â”‚   â”œâ”€â”€ preprocessing.yaml
â”‚   â”œâ”€â”€ split.yaml
â”‚   â””â”€â”€ models.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                    # Raw dataset (read-only)
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ metadata/               # Ingestion and split metadata
â”‚   â”œâ”€â”€ models/                 # Trained model files
â”‚   â”œâ”€â”€ metrics/                # Evaluation outputs
â”‚   â”œâ”€â”€ plots/                  # Visualizations
â”‚   â””â”€â”€ logs/                   # Execution logs
â”‚
â”œâ”€â”€ tests/                      # Automated tests (pytest)
â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”œâ”€â”€ test_labels.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â””â”€â”€ conftest.py
â”‚
â””â”€â”€ README.md


---

## Dataset

- Source: UCI Machine Learning Repository â€“ Student Performance Dataset
- Format: CSV (semicolon-separated)
- Target Construction:
  - Final numeric score (G3) is deterministically mapped to:
    - LOW
    - MEDIUM
    - HIGH

The raw dataset is never modified. All transformations are performed programmatically within the pipeline.

---

## How to Run the Pipeline

### Prerequisites
- Python 3.10+
- pip

### Install dependencies

```bash
pip install pandas numpy scikit-learn xgboost matplotlib seaborn pytest
````

### Run full pipeline

```bash
python main.py run --config configs/experiment.yaml
```

### Run tests

```bash
pytest
```

---

## Outputs

After successful execution, the pipeline generates:

* Trained models (`artifacts/models/`)
* Evaluation metrics (`artifacts/metrics/metrics_summary.csv`)
* Confusion matrices and accuracy comparison plots (`artifacts/plots/`)
* Execution logs (`artifacts/logs/pipeline.log`)

All outputs are reproducible and can be regenerated by rerunning the pipeline.

---

## Design Philosophy

This project intentionally avoids:

* Jupyter notebooks in the final system
* Hardcoded parameters and paths
* Manual data manipulation

Instead, it emphasizes:

* Reproducibility
* Traceability
* Modularity
* Fair and controlled model comparison

---

## Project Type

Research-oriented software project demonstrating end-to-end machine learning system design.

---

## License

This project is developed for academic and educational purposes.

```

---